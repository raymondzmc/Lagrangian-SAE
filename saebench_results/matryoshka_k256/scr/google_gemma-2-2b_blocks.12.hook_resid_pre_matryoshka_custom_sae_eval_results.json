{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 2,
    "llm_batch_size": 16,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": true,
    "model_name": "google/gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "eaacfa38-51b5-45af-a4f5-52810b9597c7",
  "datetime_epoch_millis": 1769396688324,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.2636062570661452,
      "scr_metric_threshold_2": 0.13979803898588172,
      "scr_dir2_threshold_2": 0.1352086661531932,
      "scr_dir1_threshold_5": 0.2795369210804572,
      "scr_metric_threshold_5": 0.19755342470032902,
      "scr_dir2_threshold_5": 0.18360411261456888,
      "scr_dir1_threshold_10": 0.22330949531706232,
      "scr_metric_threshold_10": 0.24393262673506405,
      "scr_dir2_threshold_10": 0.23590119450527214,
      "scr_dir1_threshold_20": 0.27057722953809993,
      "scr_metric_threshold_20": 0.3317288361584298,
      "scr_dir2_threshold_20": 0.3154244631371372,
      "scr_dir1_threshold_50": 0.15256548750479162,
      "scr_metric_threshold_50": 0.41393536532482256,
      "scr_dir2_threshold_50": 0.38766722319647906,
      "scr_dir1_threshold_100": 0.09546284805232172,
      "scr_metric_threshold_100": 0.5053354031891524,
      "scr_dir2_threshold_100": 0.5009271845081924,
      "scr_dir1_threshold_500": 0.0815690632279322,
      "scr_metric_threshold_500": 0.5492505711250212,
      "scr_dir2_threshold_500": 0.5458689265437761
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.3389836501470921,
      "scr_metric_threshold_2": 0.02933976849787981,
      "scr_dir2_threshold_2": 0.02933976849787981,
      "scr_dir1_threshold_5": 0.38983043998318945,
      "scr_metric_threshold_5": 0.04889971131822309,
      "scr_dir2_threshold_5": 0.04889971131822309,
      "scr_dir1_threshold_10": 0.2711869201176737,
      "scr_metric_threshold_10": 0.06601455198654713,
      "scr_dir2_threshold_10": 0.06601455198654713,
      "scr_dir1_threshold_20": 0.4745760999579737,
      "scr_metric_threshold_20": 0.09535446621706206,
      "scr_dir2_threshold_20": 0.09535446621706206,
      "scr_dir1_threshold_50": 0.2881358500630395,
      "scr_metric_threshold_50": 0.18092910675658758,
      "scr_dir2_threshold_50": 0.18092910675658758,
      "scr_dir1_threshold_100": 0.32203370995377106,
      "scr_metric_threshold_100": 0.26161368872470975,
      "scr_dir2_threshold_100": 0.26161368872470975,
      "scr_dir1_threshold_500": 0.20339019008825526,
      "scr_metric_threshold_500": 0.21515893382587079,
      "scr_dir2_threshold_500": 0.21515893382587079
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.41935459061540836,
      "scr_metric_threshold_2": 0.12154702682356847,
      "scr_dir2_threshold_2": 0.12154702682356847,
      "scr_dir1_threshold_5": 0.2688169630983137,
      "scr_metric_threshold_5": 0.18232054023535268,
      "scr_dir2_threshold_5": 0.18232054023535268,
      "scr_dir1_threshold_10": 0.44085969129919544,
      "scr_metric_threshold_10": 0.22928174930717843,
      "scr_dir2_threshold_10": 0.22928174930717843,
      "scr_dir1_threshold_20": 0.03225765102568063,
      "scr_metric_threshold_20": 0.270718333019668,
      "scr_dir2_threshold_20": 0.270718333019668,
      "scr_dir1_threshold_50": -0.903226406012763,
      "scr_metric_threshold_50": 0.38121545050979255,
      "scr_dir2_threshold_50": 0.38121545050979255,
      "scr_dir1_threshold_100": -0.1075274261495205,
      "scr_metric_threshold_100": 0.5276243616993775,
      "scr_dir2_threshold_100": 0.5276243616993775,
      "scr_dir1_threshold_500": 0.3440854564017635,
      "scr_metric_threshold_500": 0.6464088288627385,
      "scr_dir2_threshold_500": 0.6464088288627385
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.32812444702731197,
      "scr_metric_threshold_2": 0.03626942845164573,
      "scr_dir2_threshold_2": 0.03626942845164573,
      "scr_dir1_threshold_5": 0.5,
      "scr_metric_threshold_5": 0.07772013764658922,
      "scr_dir2_threshold_5": 0.07772013764658922,
      "scr_dir1_threshold_10": -0.2656252619344312,
      "scr_metric_threshold_10": 0.10103620982380342,
      "scr_dir2_threshold_10": 0.10103620982380342,
      "scr_dir1_threshold_20": 0.4062493597158349,
      "scr_metric_threshold_20": 0.21761657070987436,
      "scr_dir2_threshold_20": 0.21761657070987436,
      "scr_dir1_threshold_50": 0.5312495925464404,
      "scr_metric_threshold_50": 0.18393778262987753,
      "scr_dir2_threshold_50": 0.18393778262987753,
      "scr_dir1_threshold_100": 0.3593749708961743,
      "scr_metric_threshold_100": 0.2616579202764667,
      "scr_dir2_threshold_100": 0.2616579202764667,
      "scr_dir1_threshold_500": -0.4531256111803394,
      "scr_metric_threshold_500": 0.09585492908050565,
      "scr_dir2_threshold_500": 0.09585492908050565
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.487179395741273,
      "scr_metric_threshold_2": 0.11078713756074504,
      "scr_dir2_threshold_2": 0.11078713756074504,
      "scr_dir1_threshold_5": 0.2991455647515403,
      "scr_metric_threshold_5": 0.1428572173319188,
      "scr_dir2_threshold_5": 0.1428572173319188,
      "scr_dir1_threshold_10": 0.3333336729609859,
      "scr_metric_threshold_10": 0.20116620051663153,
      "scr_dir2_threshold_10": 0.20116620051663153,
      "scr_dir1_threshold_20": 0.03418810820944566,
      "scr_metric_threshold_20": 0.30612250926869616,
      "scr_dir2_threshold_20": 0.30612250926869616,
      "scr_dir1_threshold_50": -0.37606817142094434,
      "scr_metric_threshold_50": 0.4460641384217976,
      "scr_dir2_threshold_50": 0.4460641384217976,
      "scr_dir1_threshold_100": -0.8119661690102673,
      "scr_metric_threshold_100": 0.4839650470016517,
      "scr_dir2_threshold_100": 0.4839650470016517,
      "scr_dir1_threshold_500": -0.8119661690102673,
      "scr_metric_threshold_500": 0.7434402307029959,
      "scr_dir2_threshold_500": 0.7434402307029959
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.09659098798391082,
      "scr_metric_threshold_2": 0.38202266003232044,
      "scr_dir2_threshold_2": 0.38202266003232044,
      "scr_dir1_threshold_5": 0.073863676772247,
      "scr_metric_threshold_5": 0.40823977227902025,
      "scr_dir2_threshold_5": 0.40823977227902025,
      "scr_dir1_threshold_10": 0.11363655605831906,
      "scr_metric_threshold_10": 0.46441948986910864,
      "scr_dir2_threshold_10": 0.46441948986910864,
      "scr_dir1_threshold_20": 0.09090924484665525,
      "scr_metric_threshold_20": 0.749063794154593,
      "scr_dir2_threshold_20": 0.749063794154593,
      "scr_dir1_threshold_50": 0.30681819336349914,
      "scr_metric_threshold_50": 0.8052435117446815,
      "scr_dir2_threshold_50": 0.8052435117446815,
      "scr_dir1_threshold_100": -0.32386342277526586,
      "scr_metric_threshold_100": 0.8651687224314586,
      "scr_dir2_threshold_100": 0.8651687224314586,
      "scr_dir1_threshold_500": -0.06249985183509432,
      "scr_metric_threshold_500": 0.8988763743948287,
      "scr_dir2_threshold_500": 0.8988763743948287
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.16346167623110777,
      "scr_metric_threshold_2": 0.08189650632078853,
      "scr_dir2_threshold_2": 0.08189650632078853,
      "scr_dir1_threshold_5": 0.18269247852657364,
      "scr_metric_threshold_5": 0.15517243594107877,
      "scr_dir2_threshold_5": 0.15517243594107877,
      "scr_dir1_threshold_10": 0.3173078080341305,
      "scr_metric_threshold_10": 0.20258612162684675,
      "scr_dir2_threshold_10": 0.20258612162684675,
      "scr_dir1_threshold_20": 0.384615472787909,
      "scr_metric_threshold_20": 0.28017233959738613,
      "scr_dir2_threshold_20": 0.28017233959738613,
      "scr_dir1_threshold_50": 0.4903847421326191,
      "scr_metric_threshold_50": 0.37931025623568493,
      "scr_dir2_threshold_50": 0.37931025623568493,
      "scr_dir1_threshold_100": 0.4759615687708437,
      "scr_metric_threshold_100": 0.5948274998297928,
      "scr_dir2_threshold_100": 0.5948274998297928,
      "scr_dir1_threshold_500": 0.4519231375416874,
      "scr_metric_threshold_500": 0.6594825958330711,
      "scr_dir2_threshold_500": 0.6594825958330711
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.21428575483308432,
      "scr_metric_threshold_2": 0.29565223025013215,
      "scr_dir2_threshold_2": 0.29565223025013215,
      "scr_dir1_threshold_5": 0.35238089291147634,
      "scr_metric_threshold_5": 0.3956522302501322,
      "scr_dir2_threshold_5": 0.3956522302501322,
      "scr_dir1_threshold_10": 0.3714285471001494,
      "scr_metric_threshold_10": 0.4826086618499207,
      "scr_dir2_threshold_10": 0.4826086618499207,
      "scr_dir1_threshold_20": 0.4809523458113269,
      "scr_metric_threshold_20": 0.473913122350185,
      "scr_dir2_threshold_20": 0.473913122350185,
      "scr_dir1_threshold_50": 0.5571429625660193,
      "scr_metric_threshold_50": 0.6086955394997356,
      "scr_dir2_threshold_50": 0.6086955394997356,
      "scr_dir1_threshold_100": 0.4714286606327855,
      "scr_metric_threshold_100": 0.6695650934497093,
      "scr_dir2_threshold_100": 0.6695650934497093,
      "scr_dir1_threshold_500": 0.5285713393672145,
      "scr_metric_threshold_500": 0.6826086618499208,
      "scr_dir2_threshold_500": 0.6826086618499208
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.060869553949973565,
      "scr_metric_threshold_2": 0.060869553949973565,
      "scr_dir2_threshold_2": 0.02415457128846552,
      "scr_dir1_threshold_5": 0.1695653526003172,
      "scr_metric_threshold_5": 0.1695653526003172,
      "scr_dir2_threshold_5": 0.0579708559142361,
      "scr_dir1_threshold_10": 0.2043480289004758,
      "scr_metric_threshold_10": 0.2043480289004758,
      "scr_dir2_threshold_10": 0.1400965710621406,
      "scr_dir1_threshold_20": 0.2608695539499736,
      "scr_metric_threshold_20": 0.2608695539499736,
      "scr_dir2_threshold_20": 0.13043456977963266,
      "scr_dir1_threshold_50": 0.32608713680042295,
      "scr_metric_threshold_50": 0.32608713680042295,
      "scr_dir2_threshold_50": 0.11594199977367507,
      "scr_dir1_threshold_100": 0.37826089210005287,
      "scr_metric_threshold_100": 0.37826089210005287,
      "scr_dir2_threshold_100": 0.3429951426523727,
      "scr_dir1_threshold_500": 0.4521740144502379,
      "scr_metric_threshold_500": 0.4521740144502379,
      "scr_dir2_threshold_500": 0.4251208578002772
    }
  ],
  "sae_bench_commit_hash": "a62015fa6d4f4e93e25cfeaafc350eef7b2ab273",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "google/gemma-2-2b_blocks.12.hook_resid_pre_matryoshka",
  "sae_lens_version": "6.30.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 65536,
    "hook_layer": 12,
    "hook_name": "blocks.12.hook_resid_pre",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "lagrangian_sae_matryoshka",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": 512000000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}