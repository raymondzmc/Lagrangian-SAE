{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 2,
    "llm_batch_size": 16,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": true,
    "model_name": "google/gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "a1b6e138-eaff-4515-952e-8115f8d29d5a",
  "datetime_epoch_millis": 1769406886218,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.1787404557724326,
      "scr_metric_threshold_2": 0.09327758979411487,
      "scr_dir2_threshold_2": 0.08385726467619514,
      "scr_dir1_threshold_5": 0.23275766067929188,
      "scr_metric_threshold_5": 0.1401147644673093,
      "scr_dir2_threshold_5": 0.13292875124654563,
      "scr_dir1_threshold_10": 0.1797636332076392,
      "scr_metric_threshold_10": 0.2022203216629363,
      "scr_dir2_threshold_10": 0.19473238428215583,
      "scr_dir1_threshold_20": -0.003195015560448544,
      "scr_metric_threshold_20": 0.24859429110654493,
      "scr_dir2_threshold_20": 0.2510701264321397,
      "scr_dir1_threshold_50": 0.11573349421022483,
      "scr_metric_threshold_50": 0.29443660384829323,
      "scr_dir2_threshold_50": 0.29093419098016776,
      "scr_dir1_threshold_100": -0.39962883217129075,
      "scr_metric_threshold_100": 0.34874762362592826,
      "scr_dir2_threshold_100": 0.34379588990849463,
      "scr_dir1_threshold_500": -0.8960778529945344,
      "scr_metric_threshold_500": 0.2939596224423271,
      "scr_dir2_threshold_500": 0.2775948635561864
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.2711869201176737,
      "scr_metric_threshold_2": 0.11246930688538609,
      "scr_dir2_threshold_2": 0.11246930688538609,
      "scr_dir1_threshold_5": 0.2881358500630395,
      "scr_metric_threshold_5": 0.12469438044757698,
      "scr_dir2_threshold_5": 0.12469438044757698,
      "scr_dir1_threshold_10": 0.3559325800924579,
      "scr_metric_threshold_10": 0.12469438044757698,
      "scr_dir2_threshold_10": 0.12469438044757698,
      "scr_dir1_threshold_20": 0.38983043998318945,
      "scr_metric_threshold_20": 0.09779942263644618,
      "scr_dir2_threshold_20": 0.09779942263644618,
      "scr_dir1_threshold_50": 0.3559325800924579,
      "scr_metric_threshold_50": 0.08801945122627454,
      "scr_dir2_threshold_50": 0.08801945122627454,
      "scr_dir1_threshold_100": -1.6271174797142212,
      "scr_metric_threshold_100": 0.07090461055795051,
      "scr_dir2_threshold_100": 0.07090461055795051,
      "scr_dir1_threshold_500": -2.5084739598487054,
      "scr_metric_threshold_500": -0.017114986400959153,
      "scr_dir2_threshold_500": -0.017114986400959153
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.12903188592311257,
      "scr_metric_threshold_2": 0.129834376496805,
      "scr_dir2_threshold_2": 0.129834376496805,
      "scr_dir1_threshold_5": 0.32258035571797644,
      "scr_metric_threshold_5": 0.16850840054908714,
      "scr_dir2_threshold_5": 0.16850840054908714,
      "scr_dir1_threshold_10": 0.30107525503418936,
      "scr_metric_threshold_10": 0.11878463181705394,
      "scr_dir2_threshold_10": 0.11878463181705394,
      "scr_dir1_threshold_20": -1.2258067617307395,
      "scr_metric_threshold_20": 0.11878463181705394,
      "scr_dir2_threshold_20": 0.11878463181705394,
      "scr_dir1_threshold_50": -0.07526913421364485,
      "scr_metric_threshold_50": -0.00828718501954357,
      "scr_dir2_threshold_50": -0.00828718501954357,
      "scr_dir1_threshold_100": -0.053764033529857765,
      "scr_metric_threshold_100": 0.12430942183008299,
      "scr_dir2_threshold_100": 0.12430942183008299,
      "scr_dir1_threshold_500": -0.20430166104695244,
      "scr_metric_threshold_500": -0.0055247900130290465,
      "scr_dir2_threshold_500": -0.0055247900130290465
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.3749997671693945,
      "scr_metric_threshold_2": 0.11139892572658606,
      "scr_dir2_threshold_2": 0.11139892572658606,
      "scr_dir1_threshold_5": 0.3593749708961743,
      "scr_metric_threshold_5": 0.1269429223726665,
      "scr_dir2_threshold_5": 0.1269429223726665,
      "scr_dir1_threshold_10": 0.4062493597158349,
      "scr_metric_threshold_10": 0.2383420025154397,
      "scr_dir2_threshold_10": 0.2383420025154397,
      "scr_dir1_threshold_20": 0.5,
      "scr_metric_threshold_20": 0.25647663953316896,
      "scr_dir2_threshold_20": 0.25647663953316896,
      "scr_dir1_threshold_50": -0.21874994179234863,
      "scr_metric_threshold_50": 0.31347149979038,
      "scr_dir2_threshold_50": 0.31347149979038,
      "scr_dir1_threshold_100": -2.2968748544808717,
      "scr_metric_threshold_100": 0.3601036441448084,
      "scr_dir2_threshold_100": 0.3601036441448084,
      "scr_dir1_threshold_500": -4.812499650754091,
      "scr_metric_threshold_500": 0.02331607217721419,
      "scr_dir2_threshold_500": 0.02331607217721419
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.19658124012320333,
      "scr_metric_threshold_2": 0.09329447736022667,
      "scr_dir2_threshold_2": 0.09329447736022667,
      "scr_dir1_threshold_5": 0.32478626382751535,
      "scr_metric_threshold_5": 0.15743446312809697,
      "scr_dir2_threshold_5": 0.15743446312809697,
      "scr_dir1_threshold_10": -0.3418805726529776,
      "scr_metric_threshold_10": 0.24489793790516606,
      "scr_dir2_threshold_10": 0.24489793790516606,
      "scr_dir1_threshold_20": -0.4529912875318274,
      "scr_metric_threshold_20": 0.2973760922811984,
      "scr_dir2_threshold_20": 0.2973760922811984,
      "scr_dir1_threshold_50": 0.04273500790143734,
      "scr_metric_threshold_50": 0.38775515523708487,
      "scr_dir2_threshold_50": 0.38775515523708487,
      "scr_dir1_threshold_100": -0.23931624802464066,
      "scr_metric_threshold_100": 0.4868804614059919,
      "scr_dir2_threshold_100": 0.4868804614059919,
      "scr_dir1_threshold_500": -0.04273500790143734,
      "scr_metric_threshold_500": 0.55976686416136,
      "scr_dir2_threshold_500": 0.55976686416136
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.09090924484665525,
      "scr_metric_threshold_2": 0.08614232293347698,
      "scr_dir2_threshold_2": 0.08614232293347698,
      "scr_dir1_threshold_5": 0.10227273112116639,
      "scr_metric_threshold_5": 0.18726594853864825,
      "scr_dir2_threshold_5": 0.18726594853864825,
      "scr_dir1_threshold_10": 0.12500004233283019,
      "scr_metric_threshold_10": 0.3483147848305967,
      "scr_dir2_threshold_10": 0.3483147848305967,
      "scr_dir1_threshold_20": 0.04545462242332762,
      "scr_metric_threshold_20": 0.46441948986910864,
      "scr_dir2_threshold_20": 0.46441948986910864,
      "scr_dir1_threshold_50": 0.1761364078934134,
      "scr_metric_threshold_50": 0.6217228330643684,
      "scr_dir2_threshold_50": 0.6217228330643684,
      "scr_dir1_threshold_100": 0.21022720537958833,
      "scr_metric_threshold_100": 0.7078651559978453,
      "scr_dir2_threshold_100": 0.7078651559978453,
      "scr_dir1_threshold_500": -0.11363621739567752,
      "scr_metric_threshold_500": 0.7940074789313223,
      "scr_dir2_threshold_500": 0.7940074789313223
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.10096164041101975,
      "scr_metric_threshold_2": -0.004310288350249145,
      "scr_dir2_threshold_2": -0.004310288350249145,
      "scr_dir1_threshold_5": 0.16346167623110777,
      "scr_metric_threshold_5": 0.05172423095253082,
      "scr_dir2_threshold_5": 0.05172423095253082,
      "scr_dir1_threshold_10": 0.19711536532764493,
      "scr_metric_threshold_10": 0.08620705158755136,
      "scr_dir2_threshold_10": 0.08620705158755136,
      "scr_dir1_threshold_20": 0.29807700573866464,
      "scr_metric_threshold_20": 0.30172403826514554,
      "scr_dir2_threshold_20": 0.30172403826514554,
      "scr_dir1_threshold_50": 0.12500007164017604,
      "scr_metric_threshold_50": 0.4267241988379666,
      "scr_dir2_threshold_50": 0.4267241988379666,
      "scr_dir1_threshold_100": 0.18269247852657364,
      "scr_metric_threshold_100": 0.40948278852045633,
      "scr_dir2_threshold_100": 0.40948278852045633,
      "scr_dir1_threshold_500": -0.06730766475377845,
      "scr_metric_threshold_500": 0.3189654485826558,
      "scr_dir2_threshold_500": 0.3189654485826558
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.16190491868792603,
      "scr_metric_threshold_2": 0.11304356840021147,
      "scr_dir2_threshold_2": 0.11304356840021147,
      "scr_dir1_threshold_5": 0.16666676127719673,
      "scr_metric_threshold_5": 0.16956509344970924,
      "scr_dir2_threshold_5": 0.16956509344970924,
      "scr_dir1_threshold_10": 0.2380952516110281,
      "scr_metric_threshold_10": 0.3,
      "scr_dir2_threshold_10": 0.3,
      "scr_dir1_threshold_20": 0.32857139613353253,
      "scr_metric_threshold_20": 0.36086955394997355,
      "scr_dir2_threshold_20": 0.36086955394997355,
      "scr_dir1_threshold_50": 0.3809525161102811,
      "scr_metric_threshold_50": 0.38695643159978854,
      "scr_dir2_threshold_50": 0.38695643159978854,
      "scr_dir1_threshold_100": 0.46190469162265385,
      "scr_metric_threshold_100": 0.4652173236998414,
      "scr_dir2_threshold_100": 0.4652173236998414,
      "scr_dir1_threshold_500": 0.32380955354426183,
      "scr_metric_threshold_500": 0.4217391078999471,
      "scr_dir2_threshold_500": 0.4217391078999471
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.1043480289004758,
      "scr_metric_threshold_2": 0.1043480289004758,
      "scr_dir2_threshold_2": 0.02898542795711805,
      "scr_dir1_threshold_5": 0.1347826763001586,
      "scr_metric_threshold_5": 0.1347826763001586,
      "scr_dir2_threshold_5": 0.07729457053404909,
      "scr_dir1_threshold_10": 0.15652178420010573,
      "scr_metric_threshold_10": 0.15652178420010573,
      "scr_dir2_threshold_10": 0.09661828515386207,
      "scr_dir1_threshold_20": 0.09130446050026433,
      "scr_metric_threshold_20": 0.09130446050026433,
      "scr_dir2_threshold_20": 0.11111114310502254,
      "scr_dir1_threshold_50": 0.13913044605002645,
      "scr_metric_threshold_50": 0.13913044605002645,
      "scr_dir2_threshold_50": 0.11111114310502254,
      "scr_dir1_threshold_100": 0.16521758285044938,
      "scr_metric_threshold_100": 0.16521758285044938,
      "scr_dir2_threshold_100": 0.12560371311098012,
      "scr_dir1_threshold_500": 0.25652178420010574,
      "scr_metric_threshold_500": 0.25652178420010574,
      "scr_dir2_threshold_500": 0.12560371311098012
    }
  ],
  "sae_bench_commit_hash": "bcb8cfe0e327661851a33dcd1db5ff709206b410",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "google/gemma-2-2b_blocks.12.hook_resid_pre_lagrangian",
  "sae_lens_version": "6.30.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 65536,
    "hook_layer": 12,
    "hook_name": "blocks.12.hook_resid_pre",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "lagrangian_sae_lagrangian",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": 512000000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}