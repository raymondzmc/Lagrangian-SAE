{
  "google/gemma-2-2b_blocks.12.hook_resid_pre_lagrangian_custom_sae": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 2,
      "llm_batch_size": 16,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": true,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "30dfe13d-cb89-49fe-b88f-96f0852c9678",
    "datetime_epoch_millis": 1769400255394,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.1482490129420885,
        "scr_metric_threshold_2": 0.07664385035927918,
        "scr_dir2_threshold_2": 0.07827423678587728,
        "scr_dir1_threshold_5": 0.18300456856644376,
        "scr_metric_threshold_5": 0.11892337604184462,
        "scr_dir2_threshold_5": 0.11759487167893103,
        "scr_dir1_threshold_10": -0.06937103634563574,
        "scr_metric_threshold_10": 0.17892991182606494,
        "scr_dir2_threshold_10": 0.17283084104276822,
        "scr_dir1_threshold_20": -0.29491564504923223,
        "scr_metric_threshold_20": 0.2263936181404398,
        "scr_dir2_threshold_20": 0.21787909179321446,
        "scr_dir1_threshold_50": -0.2271205156453269,
        "scr_metric_threshold_50": 0.2848757110349193,
        "scr_dir2_threshold_50": 0.28674767081087826,
        "scr_dir1_threshold_100": 0.002516177616767523,
        "scr_metric_threshold_100": 0.29585692181808043,
        "scr_dir2_threshold_100": 0.30503563681103935,
        "scr_dir1_threshold_500": -0.09777761923009763,
        "scr_metric_threshold_500": 0.30104053211682413,
        "scr_dir2_threshold_500": 0.30375791356217735
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.2711869201176737,
        "scr_metric_threshold_2": 0.022004753507092297,
        "scr_dir2_threshold_2": 0.022004753507092297,
        "scr_dir1_threshold_5": 0.32203370995377106,
        "scr_metric_threshold_5": 0.05378962415699136,
        "scr_dir2_threshold_5": 0.05378962415699136,
        "scr_dir1_threshold_10": -0.7288130798823264,
        "scr_metric_threshold_10": 0.1760390481851842,
        "scr_dir2_threshold_10": 0.1760390481851842,
        "scr_dir1_threshold_20": 0.01694994019332105,
        "scr_metric_threshold_20": 0.19070893243412412,
        "scr_dir2_threshold_20": 0.19070893243412412,
        "scr_dir1_threshold_50": -0.4237282998739211,
        "scr_metric_threshold_50": 0.18581901959535585,
        "scr_dir2_threshold_50": 0.18581901959535585,
        "scr_dir1_threshold_100": -0.16949131994956843,
        "scr_metric_threshold_100": 0.09046455337829379,
        "scr_dir2_threshold_100": 0.09046455337829379,
        "scr_dir1_threshold_500": -0.44067722981928686,
        "scr_metric_threshold_500": 0.11491440903740534,
        "scr_dir2_threshold_500": 0.11491440903740534
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.11827933558121903,
        "scr_metric_threshold_2": 0.22928174930717843,
        "scr_dir2_threshold_2": 0.22928174930717843,
        "scr_dir1_threshold_5": 0.10752678523932548,
        "scr_metric_threshold_5": 0.1519337012026141,
        "scr_dir2_threshold_5": 0.1519337012026141,
        "scr_dir1_threshold_10": 0.06451594296155629,
        "scr_metric_threshold_10": 0.15469626086282157,
        "scr_dir2_threshold_10": 0.15469626086282157,
        "scr_dir1_threshold_20": -1.4623660738033726,
        "scr_metric_threshold_20": 0.16850840054908714,
        "scr_dir2_threshold_20": 0.16850840054908714,
        "scr_dir1_threshold_50": -0.333333546970065,
        "scr_metric_threshold_50": 0.41712707955556017,
        "scr_dir2_threshold_50": 0.41712707955556017,
        "scr_dir1_threshold_100": -0.48387117448715966,
        "scr_metric_threshold_100": 0.259668588339917,
        "scr_dir2_threshold_100": 0.259668588339917,
        "scr_dir1_threshold_500": -0.5053769160811418,
        "scr_metric_threshold_500": 0.16298344588236516,
        "scr_dir2_threshold_500": 0.16298344588236516
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.3906245634426147,
        "scr_metric_threshold_2": 0.06735742174380656,
        "scr_dir2_threshold_2": 0.06735742174380656,
        "scr_dir1_threshold_5": 0.3906245634426147,
        "scr_metric_threshold_5": 0.09067349392102075,
        "scr_dir2_threshold_5": 0.09067349392102075,
        "scr_dir1_threshold_10": 0.18749941792348626,
        "scr_metric_threshold_10": 0.11398956609823495,
        "scr_dir2_threshold_10": 0.11398956609823495,
        "scr_dir1_threshold_20": 0.23437473806556883,
        "scr_metric_threshold_20": 0.16062171045266332,
        "scr_dir2_threshold_20": 0.16062171045266332,
        "scr_dir1_threshold_50": -1.5468753201420826,
        "scr_metric_threshold_50": 0.16062171045266332,
        "scr_dir2_threshold_50": 0.16062171045266332,
        "scr_dir1_threshold_100": 0.17187462165026607,
        "scr_metric_threshold_100": 0.05181342509772614,
        "scr_dir2_threshold_100": 0.05181342509772614,
        "scr_dir1_threshold_500": 0.046874388819660585,
        "scr_metric_threshold_500": 0.07512949727494034,
        "scr_dir2_threshold_500": 0.07512949727494034
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.153846232221766,
        "scr_metric_threshold_2": 0.0728864027553681,
        "scr_dir2_threshold_2": 0.0728864027553681,
        "scr_dir1_threshold_5": 0.13675243283778263,
        "scr_metric_threshold_5": 0.13411080034442102,
        "scr_dir2_threshold_5": 0.13411080034442102,
        "scr_dir1_threshold_10": -0.769230651667351,
        "scr_metric_threshold_10": 0.17201170892427517,
        "scr_dir2_threshold_10": 0.17201170892427517,
        "scr_dir1_threshold_20": -1.923077393330596,
        "scr_metric_threshold_20": 0.2215744488959673,
        "scr_dir2_threshold_20": 0.2215744488959673,
        "scr_dir1_threshold_50": -0.282051255926078,
        "scr_metric_threshold_50": 0.27988343208068,
        "scr_dir2_threshold_50": 0.27988343208068,
        "scr_dir1_threshold_100": -0.2735043562340863,
        "scr_metric_threshold_100": 0.3527696610615709,
        "scr_dir2_threshold_100": 0.3527696610615709,
        "scr_dir1_threshold_500": -0.6581199367885013,
        "scr_metric_threshold_500": 0.23615169469214548,
        "scr_dir2_threshold_500": 0.23615169469214548
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.073863676772247,
        "scr_metric_threshold_2": 0.10861438856019522,
        "scr_dir2_threshold_2": 0.10861438856019522,
        "scr_dir1_threshold_5": 0.11363655605831906,
        "scr_metric_threshold_5": 0.24719115922542542,
        "scr_dir2_threshold_5": 0.24719115922542542,
        "scr_dir1_threshold_10": 0.18750023283056608,
        "scr_metric_threshold_10": 0.3370787520172376,
        "scr_dir2_threshold_10": 0.3370787520172376,
        "scr_dir1_threshold_20": 0.1988637191050772,
        "scr_metric_threshold_20": 0.42322107495071454,
        "scr_dir2_threshold_20": 0.42322107495071454,
        "scr_dir1_threshold_50": 0.017045568074408247,
        "scr_metric_threshold_50": 0.5205994306975507,
        "scr_dir2_threshold_50": 0.5205994306975507,
        "scr_dir1_threshold_100": -0.005681743137255566,
        "scr_metric_threshold_100": 0.6067417536310277,
        "scr_dir2_threshold_100": 0.6067417536310277,
        "scr_dir1_threshold_500": -0.02840905434891938,
        "scr_metric_threshold_500": 0.6104870234893628,
        "scr_dir2_threshold_500": 0.6104870234893628
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.014423173361775439,
        "scr_metric_threshold_2": 0.004310288350249145,
        "scr_dir2_threshold_2": 0.004310288350249145,
        "scr_dir1_threshold_5": 0.09615401147732933,
        "scr_metric_threshold_5": 0.025862243934522258,
        "scr_dir2_threshold_5": 0.025862243934522258,
        "scr_dir1_threshold_10": 0.13461561606826106,
        "scr_metric_threshold_10": 0.07327592962029024,
        "scr_dir2_threshold_10": 0.07327592962029024,
        "scr_dir1_threshold_20": 0.16826930516479818,
        "scr_metric_threshold_20": 0.1508621475908296,
        "scr_dir2_threshold_20": 0.1508621475908296,
        "scr_dir1_threshold_50": 0.24038459885226707,
        "scr_metric_threshold_50": 0.28017233959738613,
        "scr_dir2_threshold_50": 0.28017233959738613,
        "scr_dir1_threshold_100": 0.24519251434666164,
        "scr_metric_threshold_100": 0.37931025623568493,
        "scr_dir2_threshold_100": 0.37931025623568493,
        "scr_dir1_threshold_500": 0.1923077363939545,
        "scr_metric_threshold_500": 0.504310416808506,
        "scr_dir2_threshold_500": 0.504310416808506
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.1333332954891213,
        "scr_metric_threshold_2": 0.07826089210005287,
        "scr_dir2_threshold_2": 0.07826089210005287,
        "scr_dir1_threshold_5": 0.21904759742235502,
        "scr_metric_threshold_5": 0.16956509344970924,
        "scr_dir2_threshold_5": 0.16956509344970924,
        "scr_dir1_threshold_10": 0.24285709420029883,
        "scr_metric_threshold_10": 0.2782608921000529,
        "scr_dir2_threshold_10": 0.2782608921000529,
        "scr_dir1_threshold_20": 0.2380952516110281,
        "scr_metric_threshold_20": 0.326086877649815,
        "scr_dir2_threshold_20": 0.326086877649815,
        "scr_dir1_threshold_50": 0.33333323872280324,
        "scr_metric_threshold_50": 0.25652178420010574,
        "scr_dir2_threshold_50": 0.25652178420010574,
        "scr_dir1_threshold_100": 0.3095237419448595,
        "scr_metric_threshold_100": 0.4,
        "scr_dir2_threshold_100": 0.4,
        "scr_dir1_threshold_500": 0.32857139613353253,
        "scr_metric_threshold_500": 0.4217391078999471,
        "scr_dir2_threshold_500": 0.4217391078999471
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.030434906550290765,
        "scr_metric_threshold_2": 0.030434906550290765,
        "scr_dir2_threshold_2": 0.04347799796307564,
        "scr_dir1_threshold_5": 0.07826089210005287,
        "scr_metric_threshold_5": 0.07826089210005287,
        "scr_dir2_threshold_5": 0.06763285719674403,
        "scr_dir1_threshold_10": 0.12608713680042294,
        "scr_metric_threshold_10": 0.12608713680042294,
        "scr_dir2_threshold_10": 0.07729457053404909,
        "scr_dir1_threshold_20": 0.1695653526003172,
        "scr_metric_threshold_20": 0.1695653526003172,
        "scr_dir2_threshold_20": 0.1014491418225146,
        "scr_dir1_threshold_50": 0.17826089210005286,
        "scr_metric_threshold_50": 0.17826089210005286,
        "scr_dir2_threshold_50": 0.19323657030772415,
        "scr_dir1_threshold_100": 0.22608713680042294,
        "scr_metric_threshold_100": 0.22608713680042294,
        "scr_dir2_threshold_100": 0.2995168567440942,
        "scr_dir1_threshold_500": 0.2826086618499207,
        "scr_metric_threshold_500": 0.2826086618499207,
        "scr_dir2_threshold_500": 0.3043477134127467
      }
    ],
    "sae_bench_commit_hash": "bcb8cfe0e327661851a33dcd1db5ff709206b410",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_blocks.12.hook_resid_pre_lagrangian",
    "sae_lens_version": "6.30.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_pre",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "lagrangian_sae_lagrangian",
      "apply_b_dec_to_input": null,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": 512000000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}