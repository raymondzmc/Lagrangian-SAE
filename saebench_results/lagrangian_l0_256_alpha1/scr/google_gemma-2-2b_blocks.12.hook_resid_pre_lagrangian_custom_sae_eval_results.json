{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 2,
    "llm_batch_size": 16,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": true,
    "model_name": "google/gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "e1f52f64-9158-4cb5-9058-aa62ef3bf50a",
  "datetime_epoch_millis": 1769407038203,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.24328874894118208,
      "scr_metric_threshold_2": 0.14429481876808475,
      "scr_dir2_threshold_2": 0.13342520519468287,
      "scr_dir1_threshold_5": 0.1579647163749228,
      "scr_metric_threshold_5": 0.19131997033558593,
      "scr_dir2_threshold_5": 0.1776725911733906,
      "scr_dir1_threshold_10": -0.11909381336750974,
      "scr_metric_threshold_10": 0.24352910484138615,
      "scr_dir2_threshold_10": 0.2223334173002922,
      "scr_dir1_threshold_20": -0.24688568008151726,
      "scr_metric_threshold_20": 0.31490184866125015,
      "scr_dir2_threshold_20": 0.2899017978013698,
      "scr_dir1_threshold_50": -0.5359303600152198,
      "scr_metric_threshold_50": 0.35156478648298106,
      "scr_dir2_threshold_50": 0.3127966592213675,
      "scr_dir1_threshold_100": -0.8392162611884861,
      "scr_metric_threshold_100": 0.3501854631770581,
      "scr_dir2_threshold_100": 0.3051975170327296,
      "scr_dir1_threshold_500": -1.010866556105357,
      "scr_metric_threshold_500": 0.25643761895398176,
      "scr_dir2_threshold_500": 0.2275124768633591
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.38983043998318945,
      "scr_metric_threshold_2": 0.03667478348866732,
      "scr_dir2_threshold_2": 0.03667478348866732,
      "scr_dir1_threshold_5": 0.38983043998318945,
      "scr_metric_threshold_5": 0.039119739908051454,
      "scr_dir2_threshold_5": 0.039119739908051454,
      "scr_dir1_threshold_10": -0.7796608799663789,
      "scr_metric_threshold_10": 0.063569595567163,
      "scr_dir2_threshold_10": 0.063569595567163,
      "scr_dir1_threshold_20": -1.10169458992015,
      "scr_metric_threshold_20": 0.17359409176580007,
      "scr_dir2_threshold_20": 0.17359409176580007,
      "scr_dir1_threshold_50": 0.4067803801765105,
      "scr_metric_threshold_50": 0.09290950979767792,
      "scr_dir2_threshold_50": 0.09290950979767792,
      "scr_dir1_threshold_100": -0.05084678983609737,
      "scr_metric_threshold_100": 0.1540341489454568,
      "scr_dir2_threshold_100": 0.1540341489454568,
      "scr_dir1_threshold_500": 0.2881358500630395,
      "scr_metric_threshold_500": 0.11491440903740534,
      "scr_dir2_threshold_500": 0.11491440903740534
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.1397844362650061,
      "scr_metric_threshold_2": 0.135359166509834,
      "scr_dir2_threshold_2": 0.135359166509834,
      "scr_dir1_threshold_5": 0.08602104364534337,
      "scr_metric_threshold_5": 0.2348067039739004,
      "scr_dir2_threshold_5": 0.2348067039739004,
      "scr_dir1_threshold_10": -0.8387098221410118,
      "scr_metric_threshold_10": 0.27900551803921164,
      "scr_dir2_threshold_10": 0.27900551803921164,
      "scr_dir1_threshold_20": -0.0430108422777692,
      "scr_metric_threshold_20": 0.3066299620654357,
      "scr_dir2_threshold_20": 0.3066299620654357,
      "scr_dir1_threshold_50": -1.3870969395897277,
      "scr_metric_threshold_50": 0.18784533024838174,
      "scr_dir2_threshold_50": 0.18784533024838174,
      "scr_dir1_threshold_100": -1.2903227046922958,
      "scr_metric_threshold_100": 0.14088412117655602,
      "scr_dir2_threshold_100": 0.14088412117655602,
      "scr_dir1_threshold_500": -3.7096779362178993,
      "scr_metric_threshold_500": -0.22375679464045645,
      "scr_dir2_threshold_500": -0.22375679464045645
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.5,
      "scr_metric_threshold_2": 0.04663198993824125,
      "scr_dir2_threshold_2": 0.04663198993824125,
      "scr_dir1_threshold_5": 0.5,
      "scr_metric_threshold_5": 0.07253885690329145,
      "scr_dir2_threshold_5": 0.07253885690329145,
      "scr_dir1_threshold_10": -1.0,
      "scr_metric_threshold_10": 0.09326413429266964,
      "scr_dir2_threshold_10": 0.09326413429266964,
      "scr_dir1_threshold_20": -0.4843752037267798,
      "scr_metric_threshold_20": 0.09326413429266964,
      "scr_dir2_threshold_20": 0.09326413429266964,
      "scr_dir1_threshold_50": -2.078124912688523,
      "scr_metric_threshold_50": 0.1243522820010176,
      "scr_dir2_threshold_50": 0.1243522820010176,
      "scr_dir1_threshold_100": -3.7812500582076516,
      "scr_metric_threshold_100": -0.06217629541669594,
      "scr_dir2_threshold_100": -0.06217629541669594,
      "scr_dir1_threshold_500": -3.6093745052349635,
      "scr_metric_threshold_500": -0.0725390113194786,
      "scr_dir2_threshold_500": -0.0725390113194786
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.25641055685010294,
      "scr_metric_threshold_2": 0.12827997153574064,
      "scr_dir2_threshold_2": 0.12827997153574064,
      "scr_dir1_threshold_5": -0.615384928887064,
      "scr_metric_threshold_5": 0.19533537170795115,
      "scr_dir2_threshold_5": 0.19533537170795115,
      "scr_dir1_threshold_10": 0.5299149130841893,
      "scr_metric_threshold_10": 0.20991261750412932,
      "scr_dir2_threshold_10": 0.20991261750412932,
      "scr_dir1_threshold_20": -1.7863249604928133,
      "scr_metric_threshold_20": 0.3177843406605342,
      "scr_dir2_threshold_20": 0.3177843406605342,
      "scr_dir1_threshold_50": -2.538461812776181,
      "scr_metric_threshold_50": 0.4285714782212792,
      "scr_dir2_threshold_50": 0.4285714782212792,
      "scr_dir1_threshold_100": -2.897436184813142,
      "scr_metric_threshold_100": 0.40524781543760324,
      "scr_dir2_threshold_100": 0.40524781543760324,
      "scr_dir1_threshold_500": -2.7264961532073926,
      "scr_metric_threshold_500": -0.30029150668553856,
      "scr_dir2_threshold_500": -0.30029150668553856
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.056818447360480306,
      "scr_metric_threshold_2": 0.41198504213735543,
      "scr_dir2_threshold_2": 0.41198504213735543,
      "scr_dir1_threshold_5": 0.11931829919557463,
      "scr_metric_threshold_5": 0.4456929173390792,
      "scr_dir2_threshold_5": 0.4456929173390792,
      "scr_dir1_threshold_10": 0.147727353544494,
      "scr_metric_threshold_10": 0.4906368253541621,
      "scr_dir2_threshold_10": 0.4906368253541621,
      "scr_dir1_threshold_20": 0.21590928717948543,
      "scr_metric_threshold_20": 0.6254683261610571,
      "scr_dir2_threshold_20": 0.6254683261610571,
      "scr_dir1_threshold_50": -0.06249985183509432,
      "scr_metric_threshold_50": 0.6779027738928103,
      "scr_dir2_threshold_50": 0.6779027738928103,
      "scr_dir1_threshold_100": -0.0681815949723499,
      "scr_metric_threshold_100": 0.5992509906760037,
      "scr_dir2_threshold_100": 0.5992509906760037,
      "scr_dir1_threshold_500": -0.02840905434891938,
      "scr_metric_threshold_500": 0.8464419266630755,
      "scr_dir2_threshold_500": 0.8464419266630755
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.16826930516479818,
      "scr_metric_threshold_2": 0.025862243934522258,
      "scr_dir2_threshold_2": 0.025862243934522258,
      "scr_dir1_threshold_5": 0.22596171205119578,
      "scr_metric_threshold_5": 0.047413942602281677,
      "scr_dir2_threshold_5": 0.047413942602281677,
      "scr_dir1_threshold_10": 0.3028846346723551,
      "scr_metric_threshold_10": 0.1379310256235685,
      "scr_dir2_threshold_10": 0.1379310256235685,
      "scr_dir1_threshold_20": 0.4326923352462215,
      "scr_metric_threshold_20": 0.21551724359410787,
      "scr_dir2_threshold_20": 0.21551724359410787,
      "scr_dir1_threshold_50": 0.447115508607997,
      "scr_metric_threshold_50": 0.3922413782029461,
      "scr_dir2_threshold_50": 0.3922413782029461,
      "scr_dir1_threshold_100": 0.4326923352462215,
      "scr_metric_threshold_100": 0.6120689101473031,
      "scr_dir2_threshold_100": 0.6120689101473031,
      "scr_dir1_threshold_500": 0.6442308739356419,
      "scr_metric_threshold_500": 0.5258621154762654,
      "scr_dir2_threshold_500": 0.5258621154762654
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.3047618993555888,
      "scr_metric_threshold_2": 0.23913044605002642,
      "scr_dir2_threshold_2": 0.23913044605002642,
      "scr_dir1_threshold_5": 0.3666667045108787,
      "scr_metric_threshold_5": 0.3043477697498678,
      "scr_dir2_threshold_5": 0.3043477697498678,
      "scr_dir1_threshold_10": 0.42857150966616864,
      "scr_metric_threshold_10": 0.4173913381500793,
      "scr_dir2_threshold_10": 0.4173913381500793,
      "scr_dir1_threshold_20": 0.5047618425892707,
      "scr_metric_threshold_20": 0.5,
      "scr_dir2_threshold_20": 0.5,
      "scr_dir1_threshold_50": 0.5857143019332337,
      "scr_metric_threshold_50": 0.5695650934497092,
      "scr_dir2_threshold_50": 0.5695650934497092,
      "scr_dir1_threshold_100": 0.5285713393672145,
      "scr_metric_threshold_100": 0.5391304460500265,
      "scr_dir2_threshold_100": 0.5391304460500265,
      "scr_dir1_threshold_500": 0.5285713393672145,
      "scr_metric_threshold_500": 0.6347826763001586,
      "scr_dir2_threshold_500": 0.6347826763001586
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.13043490655029077,
      "scr_metric_threshold_2": 0.13043490655029077,
      "scr_dir2_threshold_2": 0.04347799796307564,
      "scr_dir1_threshold_5": 0.19130446050026434,
      "scr_metric_threshold_5": 0.19130446050026434,
      "scr_dir2_threshold_5": 0.08212542720270162,
      "scr_dir1_threshold_10": 0.25652178420010574,
      "scr_metric_threshold_10": 0.25652178420010574,
      "scr_dir2_threshold_10": 0.08695628387135415,
      "scr_dir1_threshold_20": 0.2869566907503965,
      "scr_metric_threshold_20": 0.2869566907503965,
      "scr_dir2_threshold_20": 0.08695628387135415,
      "scr_dir1_threshold_50": 0.33913044605002646,
      "scr_metric_threshold_50": 0.33913044605002646,
      "scr_dir2_threshold_50": 0.02898542795711805,
      "scr_dir1_threshold_100": 0.41304356840021145,
      "scr_metric_threshold_100": 0.41304356840021145,
      "scr_dir2_threshold_100": 0.05313999924558357,
      "scr_dir1_threshold_500": 0.526087136800423,
      "scr_metric_threshold_500": 0.526087136800423,
      "scr_dir2_threshold_500": 0.29468600007544166
    }
  ],
  "sae_bench_commit_hash": "bcb8cfe0e327661851a33dcd1db5ff709206b410",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "google/gemma-2-2b_blocks.12.hook_resid_pre_lagrangian",
  "sae_lens_version": "6.30.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 65536,
    "hook_layer": 12,
    "hook_name": "blocks.12.hook_resid_pre",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "lagrangian_sae_lagrangian",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": 512000000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}