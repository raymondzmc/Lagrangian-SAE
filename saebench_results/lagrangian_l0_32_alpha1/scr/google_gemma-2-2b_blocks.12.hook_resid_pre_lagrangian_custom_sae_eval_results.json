{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 2,
    "llm_batch_size": 16,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": true,
    "model_name": "google/gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "c00971c1-65cd-444c-a94f-679fd26e3428",
  "datetime_epoch_millis": 1769400268126,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.14326185443694903,
      "scr_metric_threshold_2": 0.09217081562518503,
      "scr_dir2_threshold_2": 0.08794372918708342,
      "scr_dir1_threshold_5": 0.2188526457420517,
      "scr_metric_threshold_5": 0.14604963857345174,
      "scr_dir2_threshold_5": 0.13838053999880268,
      "scr_dir1_threshold_10": 0.00458076987542198,
      "scr_metric_threshold_10": 0.17962781858908977,
      "scr_dir2_threshold_10": 0.17823890113172575,
      "scr_dir1_threshold_20": -0.04542140356558844,
      "scr_metric_threshold_20": 0.24362804562714463,
      "scr_dir2_threshold_20": 0.23601930928706566,
      "scr_dir1_threshold_50": -0.17836919959473285,
      "scr_metric_threshold_50": 0.2977465412498684,
      "scr_dir2_threshold_50": 0.30879725545475234,
      "scr_dir1_threshold_100": -0.20937466326473636,
      "scr_metric_threshold_100": 0.2993796300264424,
      "scr_dir2_threshold_100": 0.30167428929143864,
      "scr_dir1_threshold_500": -0.46429367861224113,
      "scr_metric_threshold_500": 0.2655972140473165,
      "scr_dir2_threshold_500": 0.2521310109457197
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.22033912003362105,
      "scr_metric_threshold_2": 0.004889912838768262,
      "scr_dir2_threshold_2": 0.004889912838768262,
      "scr_dir1_threshold_5": 0.2711869201176737,
      "scr_metric_threshold_5": 0.022004753507092297,
      "scr_dir2_threshold_5": 0.022004753507092297,
      "scr_dir1_threshold_10": 0.32203370995377106,
      "scr_metric_threshold_10": 0.03178472491726394,
      "scr_dir2_threshold_10": 0.03178472491726394,
      "scr_dir1_threshold_20": 0.2542379901723079,
      "scr_metric_threshold_20": 0.06845965413856638,
      "scr_dir2_threshold_20": 0.06845965413856638,
      "scr_dir1_threshold_50": 0.11864453011347105,
      "scr_metric_threshold_50": 0.10513443762723369,
      "scr_dir2_threshold_50": 0.10513443762723369,
      "scr_dir1_threshold_100": -0.10169458992015,
      "scr_metric_threshold_100": 0.05623472630901061,
      "scr_dir2_threshold_100": 0.05623472630901061,
      "scr_dir1_threshold_500": -0.05084678983609737,
      "scr_metric_threshold_500": 0.14425417753528516,
      "scr_dir2_threshold_500": 0.14425417753528516
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.08602104364534337,
      "scr_metric_threshold_2": 0.14364651618307053,
      "scr_dir2_threshold_2": 0.14364651618307053,
      "scr_dir1_threshold_5": 0.16129017785898822,
      "scr_metric_threshold_5": 0.19337028491510375,
      "scr_dir2_threshold_5": 0.19337028491510375,
      "scr_dir1_threshold_10": 0.11827933558121903,
      "scr_metric_threshold_10": 0.22928174930717843,
      "scr_dir2_threshold_10": 0.22928174930717843,
      "scr_dir1_threshold_20": 0.09677359398723691,
      "scr_metric_threshold_20": 0.3066299620654357,
      "scr_dir2_threshold_20": 0.3066299620654357,
      "scr_dir1_threshold_50": -0.6021511509785737,
      "scr_metric_threshold_50": 0.378453055503278,
      "scr_dir2_threshold_50": 0.378453055503278,
      "scr_dir1_threshold_100": -0.5806454093845916,
      "scr_metric_threshold_100": 0.20442002959485478,
      "scr_dir2_threshold_100": 0.20442002959485478,
      "scr_dir1_threshold_500": -1.9784948993162128,
      "scr_metric_threshold_500": 0.08839779278431535,
      "scr_dir2_threshold_500": 0.08839779278431535
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.3749997671693945,
      "scr_metric_threshold_2": 0.02590671254886307,
      "scr_dir2_threshold_2": 0.02590671254886307,
      "scr_dir1_threshold_5": 0.3906245634426147,
      "scr_metric_threshold_5": 0.09585492908050565,
      "scr_dir2_threshold_5": 0.09585492908050565,
      "scr_dir1_threshold_10": 0.4218741559890551,
      "scr_metric_threshold_10": 0.10621749056710117,
      "scr_dir2_threshold_10": 0.10621749056710117,
      "scr_dir1_threshold_20": 0.5156247962732202,
      "scr_metric_threshold_20": 0.15544042970936559,
      "scr_dir2_threshold_20": 0.15544042970936559,
      "scr_dir1_threshold_50": 0.3593749708961743,
      "scr_metric_threshold_50": 0.19689113890430907,
      "scr_dir2_threshold_50": 0.19689113890430907,
      "scr_dir1_threshold_100": 0.14062502910382568,
      "scr_metric_threshold_100": 0.24611392363038634,
      "scr_dir2_threshold_100": 0.24611392363038634,
      "scr_dir1_threshold_500": -0.1250002328306055,
      "scr_metric_threshold_500": 0.18911906337317527,
      "scr_dir2_threshold_500": 0.18911906337317527
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.16239313191375768,
      "scr_metric_threshold_2": 0.05539356878037252,
      "scr_dir2_threshold_2": 0.05539356878037252,
      "scr_dir1_threshold_5": 0.23076934833264898,
      "scr_metric_threshold_5": 0.10495630875206466,
      "scr_dir2_threshold_5": 0.10495630875206466,
      "scr_dir1_threshold_10": -1.5641030212936349,
      "scr_metric_threshold_10": 0.16034987753243718,
      "scr_dir2_threshold_10": 0.16034987753243718,
      "scr_dir1_threshold_20": -1.76923116110883,
      "scr_metric_threshold_20": 0.23906710909648568,
      "scr_dir2_threshold_20": 0.23906710909648568,
      "scr_dir1_threshold_50": -1.897436184813142,
      "scr_metric_threshold_50": 0.3265305838735547,
      "scr_dir2_threshold_50": 0.3265305838735547,
      "scr_dir1_threshold_100": -1.9914531003080083,
      "scr_metric_threshold_100": 0.34402341784855034,
      "scr_dir2_threshold_100": 0.34402341784855034,
      "scr_dir1_threshold_500": -2.1367524328377825,
      "scr_metric_threshold_500": 0.15743446312809697,
      "scr_dir2_threshold_500": 0.15743446312809697
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.06250019049773588,
      "scr_metric_threshold_2": 0.35580532454726704,
      "scr_dir2_threshold_2": 0.35580532454726704,
      "scr_dir1_threshold_5": 0.11363655605831906,
      "scr_metric_threshold_5": 0.4007492325623499,
      "scr_dir2_threshold_5": 0.4007492325623499,
      "scr_dir1_threshold_10": 0.147727353544494,
      "scr_metric_threshold_10": 0.4756555226824678,
      "scr_dir2_threshold_10": 0.4756555226824678,
      "scr_dir1_threshold_20": -0.2784088003519382,
      "scr_metric_threshold_20": 0.49438209521249726,
      "scr_dir2_threshold_20": 0.49438209521249726,
      "scr_dir1_threshold_50": -0.22727243479135503,
      "scr_metric_threshold_50": 0.5992509906760037,
      "scr_dir2_threshold_50": 0.5992509906760037,
      "scr_dir1_threshold_100": -0.1818178123680274,
      "scr_metric_threshold_100": 0.6779027738928103,
      "scr_dir2_threshold_100": 0.6779027738928103,
      "scr_dir1_threshold_500": -0.3579542202614408,
      "scr_metric_threshold_500": 0.6067417536310277,
      "scr_dir2_threshold_500": 0.6067417536310277
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.05288477795270717,
      "scr_metric_threshold_2": 0.05172423095253082,
      "scr_dir2_threshold_2": 0.05172423095253082,
      "scr_dir1_threshold_5": 0.18269247852657364,
      "scr_metric_threshold_5": 0.08189650632078853,
      "scr_dir2_threshold_5": 0.08189650632078853,
      "scr_dir1_threshold_10": 0.21153853868942035,
      "scr_metric_threshold_10": 0.12068961530605822,
      "scr_dir2_threshold_10": 0.12068961530605822,
      "scr_dir1_threshold_20": 0.26442303008142337,
      "scr_metric_threshold_20": 0.21982753194435703,
      "scr_dir2_threshold_20": 0.21982753194435703,
      "scr_dir1_threshold_50": 0.29807700573866464,
      "scr_metric_threshold_50": 0.2931034615646473,
      "scr_dir2_threshold_50": 0.2931034615646473,
      "scr_dir1_threshold_100": 0.35096149713066765,
      "scr_metric_threshold_100": 0.37068967953518667,
      "scr_dir2_threshold_100": 0.37068967953518667,
      "scr_dir1_threshold_500": 0.3173078080341305,
      "scr_metric_threshold_500": 0.5344826921767637,
      "scr_dir2_threshold_500": 0.5344826921767637
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.10000011353263609,
      "scr_metric_threshold_2": 0.013043568400211467,
      "scr_dir2_threshold_2": 0.013043568400211467,
      "scr_dir1_threshold_5": 0.25714290579970117,
      "scr_metric_threshold_5": 0.12608687764981497,
      "scr_dir2_threshold_5": 0.12608687764981497,
      "scr_dir1_threshold_10": 0.2619047483889719,
      "scr_metric_threshold_10": 0.19565223025013218,
      "scr_dir2_threshold_10": 0.19565223025013218,
      "scr_dir1_threshold_20": 0.361904861921608,
      "scr_metric_threshold_20": 0.27391312235018506,
      "scr_dir2_threshold_20": 0.27391312235018506,
      "scr_dir1_threshold_50": 0.42380966707689793,
      "scr_metric_threshold_50": 0.3826086618499207,
      "scr_dir2_threshold_50": 0.3826086618499207,
      "scr_dir1_threshold_100": 0.5238094967779438,
      "scr_metric_threshold_100": 0.3304349065502908,
      "scr_dir2_threshold_100": 0.3304349065502908,
      "scr_dir1_threshold_500": 0.5,
      "scr_metric_threshold_500": 0.2869564315997885,
      "scr_dir2_threshold_500": 0.2869564315997885
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.0869566907503965,
      "scr_metric_threshold_2": 0.0869566907503965,
      "scr_dir2_threshold_2": 0.05313999924558357,
      "scr_dir1_threshold_5": 0.14347821579989425,
      "scr_metric_threshold_5": 0.14347821579989425,
      "scr_dir2_threshold_5": 0.08212542720270162,
      "scr_dir1_threshold_10": 0.1173913381500793,
      "scr_metric_threshold_10": 0.1173913381500793,
      "scr_dir2_threshold_10": 0.10627999849116714,
      "scr_dir1_threshold_20": 0.19130446050026434,
      "scr_metric_threshold_20": 0.19130446050026434,
      "scr_dir2_threshold_20": 0.13043456977963266,
      "scr_dir1_threshold_50": 0.1,
      "scr_metric_threshold_50": 0.1,
      "scr_dir2_threshold_50": 0.18840571363907163,
      "scr_dir1_threshold_100": 0.16521758285044938,
      "scr_metric_threshold_100": 0.16521758285044938,
      "scr_dir2_threshold_100": 0.18357485697041911,
      "scr_dir1_threshold_500": 0.1173913381500793,
      "scr_metric_threshold_500": 0.1173913381500793,
      "scr_dir2_threshold_500": 0.009661713337305058
    }
  ],
  "sae_bench_commit_hash": "bcb8cfe0e327661851a33dcd1db5ff709206b410",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "google/gemma-2-2b_blocks.12.hook_resid_pre_lagrangian",
  "sae_lens_version": "6.30.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 65536,
    "hook_layer": 12,
    "hook_name": "blocks.12.hook_resid_pre",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "lagrangian_sae_lagrangian",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": 512000000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}