{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 2,
    "llm_batch_size": 16,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": true,
    "model_name": "google/gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "af4a52f4-bda8-4662-a093-7a2d4b8513c8",
  "datetime_epoch_millis": 1769389834514,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.1449011176596285,
      "scr_metric_threshold_2": 0.09759759100964463,
      "scr_dir2_threshold_2": 0.08980771194175134,
      "scr_dir1_threshold_5": 0.18775942302849963,
      "scr_metric_threshold_5": 0.14770263192535285,
      "scr_dir2_threshold_5": 0.13296830156214254,
      "scr_dir1_threshold_10": 0.24396675266345774,
      "scr_metric_threshold_10": 0.1621620814808403,
      "scr_dir2_threshold_10": 0.14036252809261676,
      "scr_dir1_threshold_20": 0.2456595643514938,
      "scr_metric_threshold_20": 0.18374488651353066,
      "scr_dir2_threshold_20": 0.16116032361140495,
      "scr_dir1_threshold_50": 0.13194557054775485,
      "scr_metric_threshold_50": 0.18115201711386897,
      "scr_dir2_threshold_50": 0.15850706834689518,
      "scr_dir1_threshold_100": 0.09612555712769232,
      "scr_metric_threshold_100": 0.18091257801774147,
      "scr_dir2_threshold_100": 0.1423255944229005,
      "scr_dir1_threshold_500": -0.17117724038772958,
      "scr_metric_threshold_500": 0.10355396103294229,
      "scr_dir2_threshold_500": 0.05301045476001668
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.23728804997898684,
      "scr_metric_threshold_2": 0.019559797087708167,
      "scr_dir2_threshold_2": 0.019559797087708167,
      "scr_dir1_threshold_5": 0.15254239000420264,
      "scr_metric_threshold_5": 0.044009652746819714,
      "scr_dir2_threshold_5": 0.044009652746819714,
      "scr_dir1_threshold_10": 0.23728804997898684,
      "scr_metric_threshold_10": 0.05134466773760722,
      "scr_dir2_threshold_10": 0.05134466773760722,
      "scr_dir1_threshold_20": 0.22033912003362105,
      "scr_metric_threshold_20": 0.09290950979767792,
      "scr_dir2_threshold_20": 0.09290950979767792,
      "scr_dir1_threshold_50": 0.20339019008825526,
      "scr_metric_threshold_50": 0.019559797087708167,
      "scr_dir2_threshold_50": 0.019559797087708167,
      "scr_dir1_threshold_100": 0.06779673002941843,
      "scr_metric_threshold_100": 0.05623472630901061,
      "scr_dir2_threshold_100": 0.05623472630901061,
      "scr_dir1_threshold_500": -0.6101685497688553,
      "scr_metric_threshold_500": 0.07579452339671877,
      "scr_dir2_threshold_500": 0.07579452339671877
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.010752550341893544,
      "scr_metric_threshold_2": 0.2016574699346473,
      "scr_dir2_threshold_2": 0.2016574699346473,
      "scr_dir1_threshold_5": 0.08602104364534337,
      "scr_metric_threshold_5": 0.24309405364713693,
      "scr_dir2_threshold_5": 0.24309405364713693,
      "scr_dir1_threshold_10": 0.25806441275642017,
      "scr_metric_threshold_10": 0.26795593801315354,
      "scr_dir2_threshold_10": 0.26795593801315354,
      "scr_dir1_threshold_20": 0.2903220637821008,
      "scr_metric_threshold_20": 0.29558021738568463,
      "scr_dir2_threshold_20": 0.29558021738568463,
      "scr_dir1_threshold_50": 0.15053762751709468,
      "scr_metric_threshold_50": 0.2845304727059336,
      "scr_dir2_threshold_50": 0.2845304727059336,
      "scr_dir1_threshold_100": 0.12903188592311257,
      "scr_metric_threshold_100": 0.17955814522883817,
      "scr_dir2_threshold_100": 0.17955814522883817,
      "scr_dir1_threshold_500": -0.5806454093845916,
      "scr_metric_threshold_500": 0.1657460055425726,
      "scr_dir2_threshold_500": 0.1657460055425726
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.34374924330053214,
      "scr_metric_threshold_2": 0.02849735292051195,
      "scr_dir2_threshold_2": 0.02849735292051195,
      "scr_dir1_threshold_5": 0.3593749708961743,
      "scr_metric_threshold_5": 0.03626942845164573,
      "scr_dir2_threshold_5": 0.03626942845164573,
      "scr_dir1_threshold_10": 0.28125005820765137,
      "scr_metric_threshold_10": 0.09844556945215453,
      "scr_dir2_threshold_10": 0.09844556945215453,
      "scr_dir1_threshold_20": 0.20312421419670648,
      "scr_metric_threshold_20": 0.11658020646988382,
      "scr_dir2_threshold_20": 0.11658020646988382,
      "scr_dir1_threshold_50": 0.12499930150818353,
      "scr_metric_threshold_50": 0.13989627864709803,
      "scr_dir2_threshold_50": 0.13989627864709803,
      "scr_dir1_threshold_100": -0.04687532014208255,
      "scr_metric_threshold_100": 0.1632123508243122,
      "scr_dir2_threshold_100": 0.1632123508243122,
      "scr_dir1_threshold_500": -0.32812537834973393,
      "scr_metric_threshold_500": 0.03108799329216083,
      "scr_dir2_threshold_500": 0.03108799329216083
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.06837621641889131,
      "scr_metric_threshold_2": 0.06413998576787032,
      "scr_dir2_threshold_2": 0.06413998576787032,
      "scr_dir1_threshold_5": 0.076923116110883,
      "scr_metric_threshold_5": 0.11661814014390265,
      "scr_dir2_threshold_5": 0.11661814014390265,
      "scr_dir1_threshold_10": 0.12820502370431203,
      "scr_metric_threshold_10": 0.13119538594008082,
      "scr_dir2_threshold_10": 0.13119538594008082,
      "scr_dir1_threshold_20": 0.10256432462833696,
      "scr_metric_threshold_20": 0.16034987753243718,
      "scr_dir2_threshold_20": 0.16034987753243718,
      "scr_dir1_threshold_50": -0.16239313191375768,
      "scr_metric_threshold_50": 0.17784253773295555,
      "scr_dir2_threshold_50": 0.17784253773295555,
      "scr_dir1_threshold_100": -0.10256432462833696,
      "scr_metric_threshold_100": 0.17492712332861535,
      "scr_dir2_threshold_100": 0.17492712332861535,
      "scr_dir1_threshold_500": -0.2735043562340863,
      "scr_metric_threshold_500": 0.08454806037272887,
      "scr_dir2_threshold_500": 0.08454806037272887
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.12500004233283019,
      "scr_metric_threshold_2": 0.37078662721896133,
      "scr_dir2_threshold_2": 0.37078662721896133,
      "scr_dir1_threshold_5": 0.24431834152840481,
      "scr_metric_threshold_5": 0.4157303119956906,
      "scr_dir2_threshold_5": 0.4157303119956906,
      "scr_dir1_threshold_10": 0.25000008466566037,
      "scr_metric_threshold_10": 0.34456929173390793,
      "scr_dir2_threshold_10": 0.34456929173390793,
      "scr_dir1_threshold_20": 0.3124999365007547,
      "scr_metric_threshold_20": 0.34456929173390793,
      "scr_dir2_threshold_20": 0.34456929173390793,
      "scr_dir1_threshold_50": -0.13636352860734133,
      "scr_metric_threshold_50": 0.4157303119956906,
      "scr_dir2_threshold_50": 0.4157303119956906,
      "scr_dir1_threshold_100": -0.07954541990950256,
      "scr_metric_threshold_100": 0.4269663448090497,
      "scr_dir2_threshold_100": 0.4269663448090497,
      "scr_dir1_threshold_500": -0.11363621739567752,
      "scr_metric_threshold_500": 0.14606753362025415,
      "scr_dir2_threshold_500": 0.14606753362025415
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.18750010746026405,
      "scr_metric_threshold_2": -0.056034519302779966,
      "scr_dir2_threshold_2": -0.056034519302779966,
      "scr_dir1_threshold_5": 0.26923094557581795,
      "scr_metric_threshold_5": 0.02155169866775942,
      "scr_dir2_threshold_5": 0.02155169866775942,
      "scr_dir1_threshold_10": 0.3076922636060455,
      "scr_metric_threshold_10": 0.06465535291979195,
      "scr_dir2_threshold_10": 0.06465535291979195,
      "scr_dir1_threshold_20": 0.2596154011477329,
      "scr_metric_threshold_20": 0.10344820498854794,
      "scr_dir2_threshold_20": 0.10344820498854794,
      "scr_dir1_threshold_50": 0.3076922636060455,
      "scr_metric_threshold_50": 0.1594827242913279,
      "scr_dir2_threshold_50": 0.1594827242913279,
      "scr_dir1_threshold_100": 0.27403857450950836,
      "scr_metric_threshold_100": 0.16379301264157706,
      "scr_dir2_threshold_100": 0.16379301264157706,
      "scr_dir1_threshold_500": 0.15384613180302276,
      "scr_metric_threshold_500": 0.10344820498854794,
      "scr_dir2_threshold_500": 0.10344820498854794
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.09523827094336539,
      "scr_metric_threshold_2": 0.060869553949973565,
      "scr_dir2_threshold_2": 0.060869553949973565,
      "scr_dir1_threshold_5": 0.1571427922670651,
      "scr_metric_threshold_5": 0.1478259855497621,
      "scr_dir2_threshold_5": 0.1478259855497621,
      "scr_dir1_threshold_10": 0.2761905599883743,
      "scr_metric_threshold_10": 0.12608687764981497,
      "scr_dir2_threshold_10": 0.12608687764981497,
      "scr_dir1_threshold_20": 0.33333323872280324,
      "scr_metric_threshold_20": 0.11304356840021147,
      "scr_dir2_threshold_20": 0.11304356840021147,
      "scr_dir1_threshold_50": 0.32857139613353253,
      "scr_metric_threshold_50": 0.013043568400211467,
      "scr_dir2_threshold_50": 0.013043568400211467,
      "scr_dir1_threshold_100": 0.2619047483889719,
      "scr_metric_threshold_100": 0.0173913381500793,
      "scr_dir2_threshold_100": 0.0173913381500793,
      "scr_dir1_threshold_500": 0.1523809496777944,
      "scr_metric_threshold_500": -0.008695539499735666,
      "scr_dir2_threshold_500": -0.008695539499735666
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.09130446050026433,
      "scr_metric_threshold_2": 0.09130446050026433,
      "scr_dir2_threshold_2": 0.02898542795711805,
      "scr_dir1_threshold_5": 0.15652178420010573,
      "scr_metric_threshold_5": 0.15652178420010573,
      "scr_dir2_threshold_5": 0.03864714129442311,
      "scr_dir1_threshold_10": 0.21304356840021146,
      "scr_metric_threshold_10": 0.21304356840021146,
      "scr_dir2_threshold_10": 0.03864714129442311,
      "scr_dir1_threshold_20": 0.24347821579989426,
      "scr_metric_threshold_20": 0.24347821579989426,
      "scr_dir2_threshold_20": 0.06280171258288862,
      "scr_dir1_threshold_50": 0.23913044605002642,
      "scr_metric_threshold_50": 0.23913044605002642,
      "scr_dir2_threshold_50": 0.0579708559142361,
      "scr_dir1_threshold_100": 0.2652175828504494,
      "scr_metric_threshold_100": 0.2652175828504494,
      "scr_dir2_threshold_100": -0.04347828590827851,
      "scr_dir1_threshold_500": 0.23043490655029078,
      "scr_metric_threshold_500": 0.23043490655029078,
      "scr_dir2_threshold_500": -0.17391314363311405
    }
  ],
  "sae_bench_commit_hash": "a62015fa6d4f4e93e25cfeaafc350eef7b2ab273",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "google/gemma-2-2b_blocks.12.hook_resid_pre_topk",
  "sae_lens_version": "6.30.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 65536,
    "hook_layer": 12,
    "hook_name": "blocks.12.hook_resid_pre",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "lagrangian_sae_topk",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": 512000000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}