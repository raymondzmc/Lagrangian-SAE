# Experiment Settings
wandb_project: gemma2-2b-50M
wandb_run_name: lagrangian
wandb_tags: ["lagrangian"]
seed: 42

# Model Configuration  
tlens_model_name: "google/gemma-2-2b"
tlens_model_path: null
dtype: bfloat16

# Training Configuration
save_every_n_samples: null
eval_every_n_samples: 40_000
gradient_accumulation_steps: 1
lr: 3e-4
lr_schedule: cosine
min_lr_factor: 0.1
warmup_samples: 20_000
max_grad_norm: 10.0
log_every_n_grad_steps: 20

# Data Configuration
data:
  dataset_name: "chanind/pile-uncopyrighted-gemma-1024-abbrv-1B"
  tokenizer_name: "google/gemma-2-2b"
  context_length: 1024
  n_train_samples: 50_000
  n_eval_samples: 1_000
  train_batch_size: 8
  eval_batch_size: 8
  streaming: true
  seed: null
  is_tokenized: true
  column_name: "input_ids"
  split: "train"

# SAE Configuration - Lagrangian SAE with dual ascent sparsity control
saes:
  name: "lagrangian_sae"
  sae_type: "lagrangian"
  dict_size_to_input_ratio: null
  n_dict_components: 16384
  pretrained_sae_paths: null
  retrain_saes: false
  sae_positions:
    - blocks.12.hook_resid_pre
  init_decoder_orthogonal: true
  sparsity_coeff: null
  mse_coeff: 1.0
  # Lagrangian-specific parameters
  target_l0: 32.0  # Target maximum L0 (comparable to k=32 in TopK/BatchTopK)
  initial_alpha: 0.0  # Initial Lagrangian multiplier (>= 0)
  alpha_lr: 0.01  # Learning rate for dual ascent
  alpha_lr_down: null  # If None, uses 0.1 * alpha_lr for slower descent
  alpha_max: 1.0  # Maximum alpha
  l0_ema_momentum: 0.99  # Momentum for running mean of L0
  rho_quadratic: 0.001  # Quadratic penalty coefficient
  # Per-feature learned threshold parameters (like JumpReLU)
  initial_threshold: 0.001  # Fallback threshold if calibration is disabled
  bandwidth: 0.001  # Bandwidth for gradient approximation
  # Threshold calibration (auto-sets thresholds so initial L0 ≈ target_l0)
  calibrate_thresholds: true
  # Constraint type: true = equality (L0 ≈ target), false = inequality (L0 ≤ target)
  equality_constraint: true
  tied_encoder_init: true
  use_pre_enc_bias: true
  normalize_activations: true
  # Dead feature tracking and auxiliary loss
  dead_toks_threshold: 10_000_000
  aux_k: 512
  aux_coeff: 0.03125
