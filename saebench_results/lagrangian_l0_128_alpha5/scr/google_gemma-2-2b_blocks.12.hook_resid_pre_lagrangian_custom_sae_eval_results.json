{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 2,
    "llm_batch_size": 16,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": true,
    "model_name": "google/gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "c77bf0d8-c666-4aa5-a85f-541d67ed8e3b",
  "datetime_epoch_millis": 1769407034318,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.12111432302276827,
      "scr_metric_threshold_2": 0.10429445629838,
      "scr_dir2_threshold_2": 0.10308668250778853,
      "scr_dir1_threshold_5": 0.16930960783736548,
      "scr_metric_threshold_5": 0.13920469379591427,
      "scr_dir2_threshold_5": 0.13866116295375247,
      "scr_dir1_threshold_10": -0.07952280365350776,
      "scr_metric_threshold_10": 0.18413646322244662,
      "scr_dir2_threshold_10": 0.18214367991795302,
      "scr_dir1_threshold_20": -0.4496712083188467,
      "scr_metric_threshold_20": 0.23439764869667562,
      "scr_dir2_threshold_20": 0.23155947001343175,
      "scr_dir1_threshold_50": -0.47166038050346104,
      "scr_metric_threshold_50": 0.3148791403119159,
      "scr_dir2_threshold_50": 0.3073912116946834,
      "scr_dir1_threshold_100": -0.7206161788792702,
      "scr_metric_threshold_100": 0.37015048266603756,
      "scr_dir2_threshold_100": 0.37733645645083513,
      "scr_dir1_threshold_500": -0.9156469666173378,
      "scr_metric_threshold_500": 0.26616954616050587,
      "scr_dir2_threshold_500": 0.3167733988623134
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.18644126014288948,
      "scr_metric_threshold_2": 0.019559797087708167,
      "scr_dir2_threshold_2": 0.019559797087708167,
      "scr_dir1_threshold_5": 0.2542379901723079,
      "scr_metric_threshold_5": 0.024449855659111546,
      "scr_dir2_threshold_5": 0.024449855659111546,
      "scr_dir1_threshold_10": 0.0,
      "scr_metric_threshold_10": 0.044009652746819714,
      "scr_dir2_threshold_10": 0.044009652746819714,
      "scr_dir1_threshold_20": -0.16949131994956843,
      "scr_metric_threshold_20": 0.06845965413856638,
      "scr_dir2_threshold_20": 0.06845965413856638,
      "scr_dir1_threshold_50": 0.10169560016810526,
      "scr_metric_threshold_50": 0.17114913534641596,
      "scr_dir2_threshold_50": 0.17114913534641596,
      "scr_dir1_threshold_100": -0.10169458992015,
      "scr_metric_threshold_100": 0.17114913534641596,
      "scr_dir2_threshold_100": 0.17114913534641596,
      "scr_dir1_threshold_500": -0.01694892994536579,
      "scr_metric_threshold_500": 0.12958429328634524,
      "scr_dir2_threshold_500": 0.12958429328634524
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.1397844362650061,
      "scr_metric_threshold_2": 0.07734821275825726,
      "scr_dir2_threshold_2": 0.07734821275825726,
      "scr_dir1_threshold_5": 0.32258035571797644,
      "scr_metric_threshold_5": 0.09944753746406639,
      "scr_dir2_threshold_5": 0.09944753746406639,
      "scr_dir1_threshold_10": -1.7526887784956684,
      "scr_metric_threshold_10": 0.14917130619609958,
      "scr_dir2_threshold_10": 0.14917130619609958,
      "scr_dir1_threshold_20": -1.9354840570384437,
      "scr_metric_threshold_20": 0.18784533024838174,
      "scr_dir2_threshold_20": 0.18784533024838174,
      "scr_dir1_threshold_50": -2.3010758959443844,
      "scr_metric_threshold_50": 0.270718333019668,
      "scr_dir2_threshold_50": 0.270718333019668,
      "scr_dir1_threshold_100": -3.5591403087008047,
      "scr_metric_threshold_100": 0.3591161258039834,
      "scr_dir2_threshold_100": 0.3591161258039834,
      "scr_dir1_threshold_500": -3.9139789563546565,
      "scr_metric_threshold_500": -0.1436463515293776,
      "scr_dir2_threshold_500": -0.1436463515293776
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.23437473806556883,
      "scr_metric_threshold_2": 0.012953356274431536,
      "scr_dir2_threshold_2": 0.012953356274431536,
      "scr_dir1_threshold_5": 0.21874994179234863,
      "scr_metric_threshold_5": 0.049222784726077266,
      "scr_dir2_threshold_5": 0.049222784726077266,
      "scr_dir1_threshold_10": 0.23437473806556883,
      "scr_metric_threshold_10": 0.09585492908050565,
      "scr_dir2_threshold_10": 0.09585492908050565,
      "scr_dir1_threshold_20": 0.32812444702731197,
      "scr_metric_threshold_20": 0.22279785145317213,
      "scr_dir2_threshold_20": 0.22279785145317213,
      "scr_dir1_threshold_50": 0.2968748544808716,
      "scr_metric_threshold_50": 0.20466321443544283,
      "scr_dir2_threshold_50": 0.20466321443544283,
      "scr_dir1_threshold_100": -0.03125052386886235,
      "scr_metric_threshold_100": 0.10362685019545229,
      "scr_dir2_threshold_100": 0.10362685019545229,
      "scr_dir1_threshold_500": -0.6562498253770459,
      "scr_metric_threshold_500": 0.22797928661265704,
      "scr_dir2_threshold_500": 0.22797928661265704
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.23076934833264898,
      "scr_metric_threshold_2": 0.12827997153574064,
      "scr_dir2_threshold_2": 0.12827997153574064,
      "scr_dir1_threshold_5": 0.23931624802464066,
      "scr_metric_threshold_5": 0.145772631736259,
      "scr_dir2_threshold_5": 0.145772631736259,
      "scr_dir1_threshold_10": 0.39316248024640665,
      "scr_metric_threshold_10": 0.16909629451993496,
      "scr_dir2_threshold_10": 0.16909629451993496,
      "scr_dir1_threshold_20": -1.9572655015400415,
      "scr_metric_threshold_20": 0.18075812591177295,
      "scr_dir2_threshold_20": 0.18075812591177295,
      "scr_dir1_threshold_50": -2.2222224486406574,
      "scr_metric_threshold_50": 0.33819241526539273,
      "scr_dir2_threshold_50": 0.33819241526539273,
      "scr_dir1_threshold_100": -2.6752142456139634,
      "scr_metric_threshold_100": 0.5043732953809875,
      "scr_dir2_threshold_100": 0.5043732953809875,
      "scr_dir1_threshold_500": -2.717949253515401,
      "scr_metric_threshold_500": -0.10495630875206466,
      "scr_dir2_threshold_500": -0.10495630875206466
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.06250019049773588,
      "scr_metric_threshold_2": 0.4007492325623499,
      "scr_dir2_threshold_2": 0.4007492325623499,
      "scr_dir1_threshold_5": 0.08522750170939969,
      "scr_metric_threshold_5": 0.46067422001077346,
      "scr_dir2_threshold_5": 0.46067422001077346,
      "scr_dir1_threshold_10": 0.11363655605831906,
      "scr_metric_threshold_10": 0.49438209521249726,
      "scr_dir2_threshold_10": 0.49438209521249726,
      "scr_dir1_threshold_20": -0.4034088426847684,
      "scr_metric_threshold_20": 0.5131086677425267,
      "scr_dir2_threshold_20": 0.5131086677425267,
      "scr_dir1_threshold_50": -0.2159089485168439,
      "scr_metric_threshold_50": 0.5805244181459742,
      "scr_dir2_threshold_50": 0.5805244181459742,
      "scr_dir1_threshold_100": -0.22159069165409945,
      "scr_metric_threshold_100": 0.7003746162811749,
      "scr_dir2_threshold_100": 0.7003746162811749,
      "scr_dir1_threshold_500": -0.1931816373051801,
      "scr_metric_threshold_500": 0.8426966568047404,
      "scr_dir2_threshold_500": 0.8426966568047404
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.014423173361775439,
      "scr_metric_threshold_2": 0.02155169866775942,
      "scr_dir2_threshold_2": 0.02155169866775942,
      "scr_dir1_threshold_5": 0.08653846704924431,
      "scr_metric_threshold_5": 0.08189650632078853,
      "scr_dir2_threshold_5": 0.08189650632078853,
      "scr_dir1_threshold_10": 0.14903850286933232,
      "scr_metric_threshold_10": 0.13362073727331936,
      "scr_dir2_threshold_10": 0.13362073727331936,
      "scr_dir1_threshold_20": 0.21634616762311076,
      "scr_metric_threshold_20": 0.24568977587887927,
      "scr_dir2_threshold_20": 0.24568977587887927,
      "scr_dir1_threshold_50": 0.07211558024817304,
      "scr_metric_threshold_50": 0.3146551602324067,
      "scr_dir2_threshold_50": 0.3146551602324067,
      "scr_dir1_threshold_100": 0.21153853868942035,
      "scr_metric_threshold_100": 0.4051725001702072,
      "scr_dir2_threshold_100": 0.4051725001702072,
      "scr_dir1_threshold_500": -0.03846131803022757,
      "scr_metric_threshold_500": 0.5646552244615352,
      "scr_dir2_threshold_500": 0.5646552244615352
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.05714296256601923,
      "scr_metric_threshold_2": 0.13043490655029077,
      "scr_dir2_threshold_2": 0.13043490655029077,
      "scr_dir1_threshold_5": 0.10000011353263609,
      "scr_metric_threshold_5": 0.20434776974986785,
      "scr_dir2_threshold_5": 0.20434776974986785,
      "scr_dir1_threshold_10": 0.1523809496777944,
      "scr_metric_threshold_10": 0.31304356840021147,
      "scr_dir2_threshold_10": 0.31304356840021147,
      "scr_dir1_threshold_20": 0.22380944001162575,
      "scr_metric_threshold_20": 0.3565217842001057,
      "scr_dir2_threshold_20": 0.3565217842001057,
      "scr_dir1_threshold_50": 0.2952382141770473,
      "scr_metric_threshold_50": 0.43913044605002644,
      "scr_dir2_threshold_50": 0.43913044605002644,
      "scr_dir1_threshold_100": 0.44285703743398075,
      "scr_metric_threshold_100": 0.5478259855497621,
      "scr_dir2_threshold_100": 0.5478259855497621,
      "scr_dir1_threshold_500": 0.1333332954891213,
      "scr_metric_threshold_500": 0.5347826763001586,
      "scr_dir2_threshold_500": 0.5347826763001586
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.043478474950502236,
      "scr_metric_threshold_2": 0.043478474950502236,
      "scr_dir2_threshold_2": 0.033816284625770576,
      "scr_dir1_threshold_5": 0.047826244700370064,
      "scr_metric_threshold_5": 0.047826244700370064,
      "scr_dir2_threshold_5": 0.04347799796307564,
      "scr_dir1_threshold_10": 0.07391312235018503,
      "scr_metric_threshold_10": 0.07391312235018503,
      "scr_dir2_threshold_10": 0.0579708559142361,
      "scr_dir1_threshold_20": 0.1,
      "scr_metric_threshold_20": 0.1,
      "scr_dir2_threshold_20": 0.07729457053404909,
      "scr_dir1_threshold_50": 0.2,
      "scr_metric_threshold_50": 0.2,
      "scr_dir2_threshold_50": 0.1400965710621406,
      "scr_dir1_threshold_100": 0.1695653526003172,
      "scr_metric_threshold_100": 0.1695653526003172,
      "scr_dir2_threshold_100": 0.2270531428786976,
      "scr_dir1_threshold_500": 0.07826089210005287,
      "scr_metric_threshold_500": 0.07826089210005287,
      "scr_dir2_threshold_500": 0.48309171371451326
    }
  ],
  "sae_bench_commit_hash": "bcb8cfe0e327661851a33dcd1db5ff709206b410",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "google/gemma-2-2b_blocks.12.hook_resid_pre_lagrangian",
  "sae_lens_version": "6.30.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 65536,
    "hook_layer": 12,
    "hook_name": "blocks.12.hook_resid_pre",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "lagrangian_sae_lagrangian",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": 512000000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}