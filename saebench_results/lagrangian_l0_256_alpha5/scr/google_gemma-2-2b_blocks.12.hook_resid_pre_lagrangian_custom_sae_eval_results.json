{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 2,
    "llm_batch_size": 16,
    "llm_dtype": "bfloat16",
    "lower_vram_usage": true,
    "model_name": "google/gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "db5b6748-2773-4410-8ff2-d9d4452ff5dd",
  "datetime_epoch_millis": 1769400247368,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.17682341664641207,
      "scr_metric_threshold_2": 0.11485576366434558,
      "scr_dir2_threshold_2": 0.10960211189007706,
      "scr_dir1_threshold_5": 0.16826183895004698,
      "scr_metric_threshold_5": 0.16048857910071157,
      "scr_dir2_threshold_5": 0.1556576355790284,
      "scr_dir1_threshold_10": -0.16256841907016265,
      "scr_metric_threshold_10": 0.21492393462279627,
      "scr_dir2_threshold_10": 0.2094287209230811,
      "scr_dir1_threshold_20": -0.4992495329435631,
      "scr_metric_threshold_20": 0.2700495849749474,
      "scr_dir2_threshold_20": 0.24812925985702772,
      "scr_dir1_threshold_50": -0.6478675892535659,
      "scr_metric_threshold_50": 0.3362861859385429,
      "scr_dir2_threshold_50": 0.30512675292067604,
      "scr_dir1_threshold_100": -0.4562787659357964,
      "scr_metric_threshold_100": 0.4053800965576731,
      "scr_dir2_threshold_100": 0.3577955433580537,
      "scr_dir1_threshold_500": -0.6356977224317696,
      "scr_metric_threshold_500": 0.37931981450298846,
      "scr_dir2_threshold_500": 0.38855892146397736
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.3389836501470921,
      "scr_metric_threshold_2": 0.02689481207849568,
      "scr_dir2_threshold_2": 0.02689481207849568,
      "scr_dir1_threshold_5": 0.0,
      "scr_metric_threshold_5": 0.03422982706928319,
      "scr_dir2_threshold_5": 0.03422982706928319,
      "scr_dir1_threshold_10": -0.06779571978146316,
      "scr_metric_threshold_10": 0.10513443762723369,
      "scr_dir2_threshold_10": 0.10513443762723369,
      "scr_dir1_threshold_20": -0.7966098099117448,
      "scr_metric_threshold_20": 0.12224927829555773,
      "scr_dir2_threshold_20": 0.12224927829555773,
      "scr_dir1_threshold_50": -0.23728804997898684,
      "scr_metric_threshold_50": 0.15892420751686018,
      "scr_dir2_threshold_50": 0.15892420751686018,
      "scr_dir1_threshold_100": 0.38983043998318945,
      "scr_metric_threshold_100": 0.20782391883508328,
      "scr_dir2_threshold_100": 0.20782391883508328,
      "scr_dir1_threshold_500": 0.1694923301975237,
      "scr_metric_threshold_500": 0.23716383306559818,
      "scr_dir2_threshold_500": 0.23716383306559818
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.17204272820088176,
      "scr_metric_threshold_2": 0.09116035244452282,
      "scr_dir2_threshold_2": 0.09116035244452282,
      "scr_dir1_threshold_5": 0.17204272820088176,
      "scr_metric_threshold_5": 0.11325967715033194,
      "scr_dir2_threshold_5": 0.11325967715033194,
      "scr_dir1_threshold_10": 0.010752550341893544,
      "scr_metric_threshold_10": 0.19337028491510375,
      "scr_dir2_threshold_10": 0.19337028491510375,
      "scr_dir1_threshold_20": -0.3010758959443844,
      "scr_metric_threshold_20": 0.23756909898041495,
      "scr_dir2_threshold_20": 0.23756909898041495,
      "scr_dir1_threshold_50": -2.2258067617307393,
      "scr_metric_threshold_50": 0.14917130619609958,
      "scr_dir2_threshold_50": 0.14917130619609958,
      "scr_dir1_threshold_100": -2.92473150669655,
      "scr_metric_threshold_100": 0.3342542414379668,
      "scr_dir2_threshold_100": 0.3342542414379668,
      "scr_dir1_threshold_500": -3.3440867382221535,
      "scr_metric_threshold_500": 0.14364651618307053,
      "scr_dir2_threshold_500": 0.14364651618307053
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.4062493597158349,
      "scr_metric_threshold_2": 0.02849735292051195,
      "scr_dir2_threshold_2": 0.02849735292051195,
      "scr_dir1_threshold_5": 0.34374924330053214,
      "scr_metric_threshold_5": 0.07772013764658922,
      "scr_dir2_threshold_5": 0.07772013764658922,
      "scr_dir1_threshold_10": -0.9374998835846973,
      "scr_metric_threshold_10": 0.11917100125771984,
      "scr_dir2_threshold_10": 0.11917100125771984,
      "scr_dir1_threshold_20": -2.7187499417923484,
      "scr_metric_threshold_20": 0.2383420025154397,
      "scr_dir2_threshold_20": 0.2383420025154397,
      "scr_dir1_threshold_50": -1.843750174622954,
      "scr_metric_threshold_50": 0.25647663953316896,
      "scr_dir2_threshold_50": 0.25647663953316896,
      "scr_dir1_threshold_100": 0.14062502910382568,
      "scr_metric_threshold_100": 0.10880828535493718,
      "scr_dir2_threshold_100": 0.10880828535493718,
      "scr_dir1_threshold_500": 0.17187462165026607,
      "scr_metric_threshold_500": 0.23575120772760366,
      "scr_dir2_threshold_500": 0.23575120772760366
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.2905981556180697,
      "scr_metric_threshold_2": 0.11953355454824284,
      "scr_dir2_threshold_2": 0.11953355454824284,
      "scr_dir1_threshold_5": 0.47008559635728964,
      "scr_metric_threshold_5": 0.1545190487237568,
      "scr_dir2_threshold_5": 0.1545190487237568,
      "scr_dir1_threshold_10": -1.0683762164188912,
      "scr_metric_threshold_10": 0.2215744488959673,
      "scr_dir2_threshold_10": 0.2215744488959673,
      "scr_dir1_threshold_20": -1.3247867732689942,
      "scr_metric_threshold_20": 0.2886298490681778,
      "scr_dir2_threshold_20": 0.2886298490681778,
      "scr_dir1_threshold_50": -1.8632480766036963,
      "scr_metric_threshold_50": 0.27405260327199965,
      "scr_dir2_threshold_50": 0.27405260327199965,
      "scr_dir1_threshold_100": -2.333333672960986,
      "scr_metric_threshold_100": 0.3323615864567123,
      "scr_dir2_threshold_100": 0.3323615864567123,
      "scr_dir1_threshold_500": -2.632479237712526,
      "scr_metric_threshold_500": 0.40524781543760324,
      "scr_dir2_threshold_500": 0.40524781543760324
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.073863676772247,
      "scr_metric_threshold_2": 0.3183521794872081,
      "scr_dir2_threshold_2": 0.3183521794872081,
      "scr_dir1_threshold_5": 0.12500004233283019,
      "scr_metric_threshold_5": 0.3745318970772965,
      "scr_dir2_threshold_5": 0.3745318970772965,
      "scr_dir1_threshold_10": 0.15340909668174957,
      "scr_metric_threshold_10": 0.441947647480744,
      "scr_dir2_threshold_10": 0.441947647480744,
      "scr_dir1_threshold_20": 0.27840913901457975,
      "scr_metric_threshold_20": 0.5093633978841915,
      "scr_dir2_threshold_20": 0.5093633978841915,
      "scr_dir1_threshold_50": -0.051136026897941646,
      "scr_metric_threshold_50": 0.6292135960193923,
      "scr_dir2_threshold_50": 0.6292135960193923,
      "scr_dir1_threshold_100": -0.24431800286576327,
      "scr_metric_threshold_100": 0.7865169392146519,
      "scr_dir2_threshold_100": 0.7865169392146519,
      "scr_dir1_threshold_500": 0.03977287928607206,
      "scr_metric_threshold_500": 0.8426966568047404,
      "scr_dir2_threshold_500": 0.8426966568047404
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.014423173361775439,
      "scr_metric_threshold_2": 0.04310339733551884,
      "scr_dir2_threshold_2": 0.04310339733551884,
      "scr_dir1_threshold_5": 0.06730795131448261,
      "scr_metric_threshold_5": 0.0905173399378005,
      "scr_dir2_threshold_5": 0.0905173399378005,
      "scr_dir1_threshold_10": 0.2019232808220395,
      "scr_metric_threshold_10": 0.10775875025531079,
      "scr_dir2_threshold_10": 0.10775875025531079,
      "scr_dir1_threshold_20": 0.26923094557581795,
      "scr_metric_threshold_20": 0.11206903860555993,
      "scr_dir2_threshold_20": 0.11206903860555993,
      "scr_dir1_threshold_50": 0.3028846346723551,
      "scr_metric_threshold_50": 0.41810336522095465,
      "scr_dir2_threshold_50": 0.41810336522095465,
      "scr_dir1_threshold_100": 0.40865390401706525,
      "scr_metric_threshold_100": 0.5732758011620334,
      "scr_dir2_threshold_100": 0.5732758011620334,
      "scr_dir1_threshold_500": 0.033653975657241306,
      "scr_metric_threshold_500": 0.4439656091554769,
      "scr_dir2_threshold_500": 0.4439656091554769
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.06190480515528994,
      "scr_metric_threshold_2": 0.2347826763001586,
      "scr_dir2_threshold_2": 0.2347826763001586,
      "scr_dir1_threshold_5": 0.08095245934396302,
      "scr_metric_threshold_5": 0.3521740144502379,
      "scr_dir2_threshold_5": 0.3521740144502379,
      "scr_dir1_threshold_10": 0.280952402577645,
      "scr_metric_threshold_10": 0.40434776974986786,
      "scr_dir2_threshold_10": 0.40434776974986786,
      "scr_dir1_threshold_20": 0.3952380438780932,
      "scr_metric_threshold_20": 0.4478259855497621,
      "scr_dir2_threshold_20": 0.4478259855497621,
      "scr_dir1_threshold_50": 0.45714284903338315,
      "scr_metric_threshold_50": 0.526086877649815,
      "scr_dir2_threshold_50": 0.526086877649815,
      "scr_dir1_threshold_100": 0.600000113532636,
      "scr_metric_threshold_100": 0.5869564315997885,
      "scr_dir2_threshold_100": 0.5869564315997885,
      "scr_dir1_threshold_500": 0.37619038968942015,
      "scr_metric_threshold_500": 0.626086877649815,
      "scr_dir2_threshold_500": 0.626086877649815
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.056521784200105736,
      "scr_metric_threshold_2": 0.056521784200105736,
      "scr_dir2_threshold_2": 0.014492570005957587,
      "scr_dir1_threshold_5": 0.0869566907503965,
      "scr_metric_threshold_5": 0.0869566907503965,
      "scr_dir2_threshold_5": 0.04830914257693104,
      "scr_dir1_threshold_10": 0.12608713680042294,
      "scr_metric_threshold_10": 0.12608713680042294,
      "scr_dir2_threshold_10": 0.08212542720270162,
      "scr_dir1_threshold_20": 0.2043480289004758,
      "scr_metric_threshold_20": 0.2043480289004758,
      "scr_dir2_threshold_20": 0.02898542795711805,
      "scr_dir1_threshold_50": 0.2782608921000529,
      "scr_metric_threshold_50": 0.2782608921000529,
      "scr_dir2_threshold_50": 0.02898542795711805,
      "scr_dir1_threshold_100": 0.31304356840021147,
      "scr_metric_threshold_100": 0.31304356840021147,
      "scr_dir2_threshold_100": -0.06763285719674403,
      "scr_dir1_threshold_500": 0.1,
      "scr_metric_threshold_500": 0.1,
      "scr_dir2_threshold_500": 0.17391285568791118
    }
  ],
  "sae_bench_commit_hash": "bcb8cfe0e327661851a33dcd1db5ff709206b410",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "google/gemma-2-2b_blocks.12.hook_resid_pre_lagrangian",
  "sae_lens_version": "6.30.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 65536,
    "hook_layer": 12,
    "hook_name": "blocks.12.hook_resid_pre",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "lagrangian_sae_lagrangian",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": 512000000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}